{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdf6ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samruddhi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981730b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x): # here input is a vector\n",
    "    return 1 / (1 + (np.e) ** (-x)) \n",
    "\n",
    "def exp (y) :\n",
    "    return (np.e)**y\n",
    "\n",
    "def Softmax(x):\n",
    "    return exp(x) / np.sum(exp(x))\n",
    "\n",
    "def Diff_Sigmoid(x) :\n",
    "    return np.multiply(Sigmoid(x), (Sigmoid(x) - np.ones(x.shape)))\n",
    "\n",
    "def Reshape (vector):\n",
    "    return vector.reshape(vector.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89fcb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output_Layer:\n",
    "    def __init__(self, neurons, prev_layer_neurons):\n",
    "        self.neurons = neurons\n",
    "        self.weights = np.random.rand(neurons, prev_layer_neurons) - 0.5\n",
    "        self.biases = np.random.rand(neurons) - 0.5\n",
    "        self.g_weights = np.zeros(self.weights.shape)\n",
    "        self.g_biases = np.zeros(self.biases.shape)\n",
    "    \n",
    "    def change_weights(self, prev_layer_neurons):\n",
    "        self.weights = np.random.rand(self.neurons, prev_layer_neurons)\n",
    "        self.g_weights = np.zeros(self.weights.shape)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        self.pre_activation = np.dot(self.weights, input_) + self.biases\n",
    "        self.post_activation = Softmax(self.pre_activation)\n",
    "        return self.post_activation\n",
    "    \n",
    "    def backward(self, output_true, output_pred, prev_post_activation, prev_pre_activation):\n",
    "        self.grad_a_Ltheta = -(np.subtract(output_true, output_pred))\n",
    "        self.grad_W_Ltheta = np.matmul(Reshape(self.grad_a_Ltheta), np.transpose(Reshape(prev_post_activation)))\n",
    "        self.grad_b_Ltheta = self.grad_a_Ltheta\n",
    "        self.grad_prev_post_activation_Ltheta = np.ndarray.flatten(np.matmul(np.transpose(self.weights), Reshape(self.grad_a_Ltheta)))\n",
    "        self.dg = Diff_Sigmoid(prev_pre_activation)\n",
    "        self.grad_a_Ltheta = np.ndarray.flatten(np.multiply(Reshape(self.grad_prev_post_activation_Ltheta), Reshape(self.dg)))\n",
    "        return self.grad_a_Ltheta\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9b87465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hidden_Layer:\n",
    "       def __init__(self, neurons, prev_layer_neurons):\n",
    "        self.neurons = neurons\n",
    "        self.weights = np.random.rand(neurons, prev_layer_neurons) - 0.5\n",
    "        self.biases = np.random.rand(neurons) - 0.5\n",
    "        self.g_weights = np.zeros(self.weights.shape)\n",
    "        self.g_biases = np.zeros(self.biases.shape)\n",
    "\n",
    "        def forward(self, input_):\n",
    "            self.pre_activation = np.dot(self.weights, input_) + self.biases\n",
    "            self.post_activation = Sigmoid(self.pre_activation)\n",
    "            return self.post_activation\n",
    "\n",
    "        def backward(self, next_grad_a_LTheta, prev_pre_activation, prev_post_activation):\n",
    "\n",
    "            self.grad_W_Ltheta = np.matmul(Reshape(next_grad_a_LTheta), np.transpose(Reshape(prev_post_activation)))\n",
    "            self.grad_b_Ltheta = next_grad_a_LTheta\n",
    "            self.grad_prev_post_activation_Ltheta= np.ndarray.flatten(np.dot(np.transpose(self.weights), Reshape(next_grad_a_LTheta)))\n",
    "            self.dg = Diff_Sigmoid(prev_pre_activation)\n",
    "            self.grad_a_Ltheta = np.ndarray.flatten(np.multiply(Reshape(self.grad_prev_post_activation_Ltheta), Reshape(self.dg)))\n",
    "            return self.grad_a_Ltheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b695bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    def __init__(self, input_, outputs_, learning_rate):\n",
    "        self.real_outputs = outputs_\n",
    "        self.input_layer = input_ # this is the input vector\n",
    "        self.ip_dim = input_.shape[1] * input_.shape[2]\n",
    "        self.layers = []\n",
    "        self.add_default_layers(self.ip_dim, 10)\n",
    "        self.eta = learning_rate\n",
    "        \n",
    "    def add_default_layers(self, input_dim, output_dim):\n",
    "        self.output_layer = Output_Layer(output_dim, input_dim)\n",
    "    \n",
    "    def add_hidden_layer(self, no_of_neurons):\n",
    "        if(len(self.layers) == 0):\n",
    "            new_layer = Hidden_Layer(no_of_neurons, self.ip_dim)\n",
    "        else:\n",
    "            new_layer = Hidden_Layer(no_of_neurons, self.layers[-1].neurons)\n",
    "        self.layers.append(new_layer)\n",
    "        # changing the weights of output layer each time a new hidden layer is added\n",
    "        self.output_layer.change_weights(self.layers[-1].neurons)\n",
    "    \n",
    "    def train(self):\n",
    "        i = 0\n",
    "        for img in self.input_layer:\n",
    "            true_y = np.zeros(10)\n",
    "            true_y[self.real_outputs[i]] = 1\n",
    "            activation = np.ndarray.flatten(img)\n",
    "            \n",
    "            for x in range(len(self.layers)):\n",
    "                activation = self.layers[x].forward(activation)\n",
    "            \n",
    "            op = self.output_layer.forward(activation)\n",
    "\n",
    "            loss = -1 *  np.log(op[self.real_outputs[i]])\n",
    "            if(i == 0):\n",
    "                print(\"LOSS=\",loss)\n",
    "            i += 1\n",
    "            self.prev_post_activation = self.layers[-1].post_activation\n",
    "            self.prev_pre_activation =   self.layers[-1].pre_activation\n",
    "\n",
    "            \n",
    "            self.grad_a_Ltheta = self.output_layer.backward(true_y, op, self.prev_post_activation, self.prev_pre_activation)\n",
    "            self.output_layer.g_weights += self.output_layer.grad_W_Ltheta # (10, 100)\n",
    "            self.output_layer.g_biases += self.output_layer.grad_b_Ltheta # (10, )\n",
    "           \n",
    "\n",
    "            for x in range(len(self.layers)-1,-1,-1):\n",
    "                if x==0:\n",
    "                    post_activation = np.ndarray.flatten(img)\n",
    "                    pre_activation = np.zeros(post_activation.shape)\n",
    "                else:\n",
    "                    pre_activation = self.layers[x-1].pre_activation # previous layer a(k-1) \n",
    "                    post_activation = self.layers[x-1].post_activation # previous layer h(k-1)\n",
    "                \n",
    "                \n",
    "                self.grad_a_Ltheta = self.layers[x].backward(self.grad_a_Ltheta, pre_activation, post_activation)\n",
    "                self.layers[x].g_weights += self.layers[x].grad_W_Ltheta              \n",
    "                self.layers[x].g_biases += self.layers[x].grad_b_Ltheta\n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "(train_x, train_Y), (test_x, test_Y) = fashion_mnist.load_data()\n",
    "\n",
    "    \n",
    "ann = FFNN(train_x[:3]/255, train_Y, 0.001)\n",
    "ann.add_hidden_layer(200)\n",
    "ann.add_hidden_layer(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
